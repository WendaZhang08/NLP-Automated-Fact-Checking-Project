{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_RZ3Oy5ylIE"
      },
      "source": [
        "# 0.Setting Colab Method for future model developing\n",
        "Firstly, run the following block to mount the drive to the colab. Then, drag the data folder/**eval.py** to the \"Colab Folder Space\" to ensure the code runs successfully.\n",
        "\n",
        "If data folder updated, attempt to forcibly remount, call `drive.mount(\"/content/drive\", force_remount=True)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBH7j4IHspgB",
        "outputId": "56611668-da3f-4157-9707-111dd751cc29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRmNYMfb1g2"
      },
      "source": [
        "## 1.1 Reading and gathering data\n",
        "\n",
        "Using `json` package reading and gathering claims and evidences, then print an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1N-PVoLb1g2",
        "outputId": "15670b2e-7fef-46f2-ae24-dea4041f043a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "claim count:  1228\n",
            "evidence count:  1208827\n",
            "max claim length:  332\n",
            "min claim length:  26\n",
            "mean claim length:  122.95521172638436\n",
            "max evidence count:  5\n",
            "min evidence count:  1\n",
            "mean evidence count:  3.3566775244299674\n",
            "max evidence length:  1979\n",
            "min evidence length:  13\n",
            "mean evidence length:  173.5\n",
            "Counter({'SUPPORTS': 519, 'NOT_ENOUGH_INFO': 386, 'REFUTES': 199, 'DISPUTED': 124})\n",
            "Dev evi inside train evi 154\n",
            "Dev evi outside train evi 0\n",
            "Train claim count:  1228\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from statistics import mean\n",
        "\n",
        "with open('data/train-claims.json', 'r') as input_file:\n",
        "    train_claim_data = json.load(input_file)\n",
        "\n",
        "# Read in development data (claim)\n",
        "with open('data/dev-claims.json', 'r') as input_file:\n",
        "    dev_claim_data = json.load(input_file)\n",
        "\n",
        "# Read in test data (claim)\n",
        "with open('data/test-claims-unlabelled.json', 'r') as input_file:\n",
        "    test_claim_data = json.load(input_file)\n",
        "\n",
        "# Read in evidence data\n",
        "with open('data/evidence.json', 'r') as input_file:\n",
        "    evi_data = json.load(input_file)\n",
        "\n",
        "#EDA\n",
        "\n",
        "\n",
        "claim_count = 0\n",
        "evi_count = 0\n",
        "claim_length = []\n",
        "evidence_count = []\n",
        "evidence_length = []\n",
        "labels = []\n",
        "\n",
        "for key,value in train_claim_data.items():\n",
        "    claim_count+=1\n",
        "    claim_length.append(len(value[\"claim_text\"]))\n",
        "    evidence_count.append(len(value[\"evidences\"]))\n",
        "    evidence_length += [len(evi_data[x]) for x in value[\"evidences\"]]\n",
        "    labels.append(value[\"claim_label\"])\n",
        "\n",
        "for key,value in evi_data.items():\n",
        "    evi_count+=1\n",
        "\n",
        "print(\"claim count: \",claim_count)\n",
        "print(\"evidence count: \",evi_count)\n",
        "print(\"max claim length: \",max(claim_length))\n",
        "print(\"min claim length: \",min(claim_length))\n",
        "print(\"mean claim length: \",mean(claim_length))\n",
        "print(\"max evidence count: \",max(evidence_count))\n",
        "print(\"min evidence count: \",min(evidence_count))\n",
        "print(\"mean evidence count: \",mean(evidence_count))\n",
        "print(\"max evidence length: \",max(evidence_length))\n",
        "print(\"min evidence length: \",min(evidence_length))\n",
        "print(\"mean evidence length: \",mean(evidence_length))\n",
        "print(Counter(labels))\n",
        "\n",
        "\n",
        "\n",
        "inside = 0\n",
        "outside = 0\n",
        "\n",
        "train_evi_id = []\n",
        "for claim_id,claim_value in train_claim_data.items():\n",
        "    train_evi_id=train_evi_id+claim_value['evidences']\n",
        "\n",
        "for claim_id,claim_value in dev_claim_data.items():\n",
        "    test_evi_id=claim_value['evidences']\n",
        "    for e in test_evi_id:\n",
        "        if e in train_evi_id:\n",
        "            inside += 1\n",
        "        else:\n",
        "            outside += 1\n",
        "print(\"Dev evi inside train evi\", inside)\n",
        "print(\"Dev evi outside train evi\", outside)\n",
        "\n",
        "full_evidence_id = list(evi_data.keys())\n",
        "full_evidence_text  = list(evi_data.values())\n",
        "train_claim_id = list(train_claim_data.keys())\n",
        "train_claim_text  = [ v[\"claim_text\"] for v in train_claim_data.values()]\n",
        "print(\"Train claim count: \",len(train_claim_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpCxJ35-b1g3"
      },
      "source": [
        "## 1.2 Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGFcmSZmDlfE"
      },
      "source": [
        "### Implementing preprocessing fuctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYaLwC2MDlfF",
        "outputId": "10c41a64-59c6-428f-88c3-7a11e794c2b2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\ABC\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\ABC\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def lemmatize(word):\n",
        "    lemma = lemmatizer.lemmatize(word, 'v')\n",
        "    return lemma if lemma != word else lemmatizer.lemmatize(word, 'n')\n",
        "\n",
        "def is_pure_english(text):\n",
        "    english_letters = set(string.ascii_letters)\n",
        "    cleaned_text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
        "    return all(char in english_letters or char.isspace() for char in cleaned_text)\n",
        "\n",
        "def remove_non_eng(dictionary):\n",
        "    eng_data = {}\n",
        "    for key, value in dictionary.items():\n",
        "        if is_pure_english(value):\n",
        "            eng_data[key] = value\n",
        "    return eng_data\n",
        "\n",
        "def contains_climate_keywords(text, keywords):\n",
        "    text = text.lower()\n",
        "    for keyword in keywords:\n",
        "        if re.search(r\"\\b\" + re.escape(keyword) + r\"\\b\", text):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def filter_climate_related(dictionary, keywords):\n",
        "    cs_data = {}\n",
        "    for key, value in dictionary.items():\n",
        "        if contains_climate_keywords(value, keywords):\n",
        "            cs_data[key] = value\n",
        "    return cs_data\n",
        "\n",
        "def text_preprocessing(text, remove_stopwords=False):\n",
        "    words = [lemmatize(w) for w in text.lower().split()]\n",
        "    if remove_stopwords:\n",
        "        words = [w for w in words if w not in stopwords]\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqq0xrC_DlfF"
      },
      "source": [
        "### Implementing **Claim data preprocessing** and **Evidence data preprocessing** functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nsxYPxqgDlfF"
      },
      "outputs": [],
      "source": [
        "# 权威网站 https://www.ucdavis.edu/climate/definitions\n",
        "climate_keywords = [\n",
        "    \"climate\", \"environment\", \"global warming\", \"greenhouse effect\", \"carbon\", \"co2\", \"carbon dioxide\",\n",
        "    \"methane\", \"renewable energy\", \"sustainability\", \"ecology\", \"biodiversity\", \"fossil fuels\",\n",
        "    \"emissions\", \"air quality\", \"ozone\", \"solar energy\", \"wind energy\", \"climate change\", \"climate crisis\",\n",
        "    \"climate adaptation\", \"climate mitigation\", \"ocean\", \"sea levels\", \"ice melting\", \"deforestation\",\n",
        "    \"reforestation\", \"pollution\"\n",
        "]\n",
        "\n",
        "# def filter_evidence_by_train(train_claim_data, evidence_data):\n",
        "\n",
        "#     # Collect all evidence ids in the training set\n",
        "#     train_evidence_ids = set()\n",
        "\n",
        "#     for claim in train_claim_data.values():\n",
        "#         train_evidence_ids.update(claim['evidences'])\n",
        "\n",
        "#     # filter evidence data by the evidence ids in the training set\n",
        "#     filtered_evidence_data = {key: value for key, value in evidence_data.items() if key in train_evidence_ids}\n",
        "\n",
        "#     return filtered_evidence_data\n",
        "\n",
        "def preprocess_claim_data(claim_data, existed_evidences_id=None):\n",
        "    claim_data = remove_non_eng(claim_data)\n",
        "    claim_data_text = []\n",
        "    claim_data_id = []\n",
        "    claim_data_label = []\n",
        "    claim_evidences = []\n",
        "\n",
        "    for key in claim_data.keys():\n",
        "        claim_data[key][\"claim_text\"] = text_preprocessing(claim_data[key][\"claim_text\"])\n",
        "        claim_data_text.append(claim_data[key][\"claim_text\"])\n",
        "        claim_data_id.append(key)\n",
        "\n",
        "        if \"claim_label\" in claim_data[key]:\n",
        "            claim_data_label.append(claim_data[key][\"claim_label\"])\n",
        "        else:\n",
        "            claim_data_label.append(None)\n",
        "\n",
        "        if existed_evidences_id and \"evidences\" in claim_data[key]:\n",
        "            claim_evidences.append([existed_evidences_id[i] for i in claim_data[key][\"evidences\"]])\n",
        "        else:\n",
        "            claim_evidences.append([])\n",
        "\n",
        "    return claim_data_text, claim_data_id, claim_data_label, claim_evidences\n",
        "\n",
        "# def preprocess_evi_data(evi_data, climate_keywords, train_claim_data):\n",
        "#     evi_data = remove_non_eng(evi_data)\n",
        "#     # cs_evi_data = filter_climate_related(evi_data, climate_keywords)\n",
        "\n",
        "#     # filter evidence data by the evidence ids in the training set\n",
        "#     # train_evi_data = filter_evidence_by_train(train_claim_data, cs_evi_data)\n",
        "\n",
        "#     for key in evi_data.keys():\n",
        "#         evi_data[key] = text_preprocessing(evi_data[key], remove_stopwords=True)\n",
        "\n",
        "#     cleaned_evidence_text = list(evi_data.values())\n",
        "#     cleaned_evidence_id = list(evi_data.keys())\n",
        "\n",
        "#     return cleaned_evidence_text, cleaned_evidence_id\n",
        "\n",
        "def preprocess_evi_data(evi_data):\n",
        "    evi_data = remove_non_eng(evi_data)\n",
        "    # cs_evi_data = filter_climate_related(evi_data, climate_keywords)\n",
        "\n",
        "    # filter evidence data by the evidence ids in the training set\n",
        "    # train_evi_data = filter_evidence_by_train(train_claim_data, cs_evi_data)\n",
        "\n",
        "    for key in evi_data.keys():\n",
        "        evi_data[key] = text_preprocessing(evi_data[key], remove_stopwords=True)\n",
        "\n",
        "    cleaned_evidence_text = list(evi_data.values())\n",
        "    cleaned_evidence_id = list(evi_data.keys())\n",
        "\n",
        "    return cleaned_evidence_text, cleaned_evidence_id\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL8bIR_XDlfF"
      },
      "source": [
        "### Start dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0_ht7aH1DlfF"
      },
      "outputs": [],
      "source": [
        "# Preprocessing the claim data, split the data into text, id, label and evidences\n",
        "train_claim_text, train_claim_id, train_claim_label, train_claim_evidences = preprocess_claim_data(train_claim_data)\n",
        "\n",
        "dev_claim_text, dev_claim_id, dev_claim_label, dev_claim_evidences = preprocess_claim_data(dev_claim_data)\n",
        "\n",
        "test_claim_text, test_claim_id, _, _ = preprocess_claim_data(test_claim_data)\n",
        "\n",
        "# Preprocessing the evidence data, split the data into text and id\n",
        "# cleaned_evidence_text, cleaned_evidence_id = preprocess_evi_data(evi_data, climate_keywords, train_claim_data)\n",
        "\n",
        "cleaned_evidence_text, cleaned_evidence_id = preprocess_evi_data(evi_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL0R-_jaCJfv",
        "outputId": "8d6c6be2-fd20-4082-b8a3-1e2fae025416"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train claim count:  1228\n",
            "Dev claim count:  154\n",
            "Test claim count:  153\n",
            "Evidence count:  1114577\n"
          ]
        }
      ],
      "source": [
        "print(\"Train claim count: \",len(train_claim_text))\n",
        "print(\"Dev claim count: \",len(dev_claim_text))\n",
        "print(\"Test claim count: \",len(test_claim_text))\n",
        "print(\"Evidence count: \",len(cleaned_evidence_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3LL9-aEb1g5"
      },
      "source": [
        "## 1.3 Development Set Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g4cbdtTb1g5"
      },
      "source": [
        "In this section, we perform the main tasks of the project on the development set:\n",
        "\n",
        "1. **Evidence Retrieval**: For each claim, find the most relevant evidence from the corpus.\n",
        "2. **Claim Classification**: Predict the label for each claim based on the retrieved evidence and the claim's similarity to the training claims.\n",
        "\n",
        "The code uses TF-IDF vectorization and cosine similarity to measure the relevance between claims and evidence, and between development and training claims. The most similar evidence and training claims are used for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# Creating two vectorizer\n",
        "evidence_tfidf_vectorizer = TfidfVectorizer(max_features=400000, use_idf=True)\n",
        "\n",
        "# fit the vectorizer on the evidence data\n",
        "evidence_tfidf_vectorizer.fit(cleaned_evidence_text)\n",
        "\n",
        "# Transform cleaned_evidence_text\n",
        "transformed_evidence = evidence_tfidf_vectorizer.transform(cleaned_evidence_text)\n",
        "\n",
        "# Transform claim data\n",
        "train_claim_tfidf = evidence_tfidf_vectorizer.transform(train_claim_text)\n",
        "dev_claim_tfidf = evidence_tfidf_vectorizer.transform(dev_claim_text)\n",
        "test_claim_tfidf = evidence_tfidf_vectorizer.transform(test_claim_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed evidence shape:  (1114577, 400000)\n",
            "Transformed train claim shape:  (1228, 400000)\n",
            "Transformed dev claim shape:  (154, 400000)\n"
          ]
        }
      ],
      "source": [
        "print(\"Transformed evidence shape: \", transformed_evidence.shape)\n",
        "print(\"Transformed train claim shape: \", train_claim_tfidf.shape)\n",
        "print(\"Transformed dev claim shape: \", dev_claim_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "58n5gcslrAmV"
      },
      "outputs": [],
      "source": [
        "# Calculate cosine similarity between train claims and evidence\n",
        "train_similarity = cosine_similarity(train_claim_tfidf, transformed_evidence)\n",
        "\n",
        "# Calculate cosine similarity between dev claims and evidence\n",
        "dev_similarity = cosine_similarity(dev_claim_tfidf, transformed_evidence)\n",
        "\n",
        "# Calculate cosine similarity between test claims and evidence\n",
        "test_similarity = cosine_similarity(test_claim_tfidf, transformed_evidence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train similarity shape:  (1228, 1114577)\n",
            "Dev similarity shape:  (1114577, 400000)\n",
            "Test similarity shape:  [[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.02440987 0.        ]\n",
            " [0.         0.         0.         ... 0.         0.02700692 0.        ]\n",
            " ...\n",
            " [0.         0.01452821 0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(\"Train similarity shape: \", train_similarity.shape)\n",
        "print(\"Dev similarity shape: \", transformed_evidence.shape)\n",
        "print(\"Test similarity shape: \", test_similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ErcyOigvPc6k",
        "outputId": "813319b1-0d8a-4c6d-f7ed-6e93574f5f6a"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-3a6a14ff729e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_claim_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_evidence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_claim_tfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_evidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate Euclidean distance between dev claims and evidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# # Calculate Euclidean distance between train claims and evidence\n",
        "# train_distance = np.zeros((train_claim_tfidf.shape[0], transformed_evidence.shape[0]))\n",
        "# for i in range(train_claim_tfidf.shape[0]):\n",
        "#     for j in range(transformed_evidence.shape[0]):\n",
        "#         train_distance[i, j] = euclidean(train_claim_tfidf[i].toarray().ravel(), transformed_evidence[j].toarray().ravel())\n",
        "\n",
        "# # Calculate Euclidean distance between dev claims and evidence\n",
        "# dev_distance = np.zeros((dev_claim_tfidf.shape[0], transformed_evidence.shape[0]))\n",
        "# for i in range(dev_claim_tfidf.shape[0]):\n",
        "#     for j in range(transformed_evidence.shape[0]):\n",
        "#         dev_distance[i, j] = euclidean(dev_claim_tfidf[i].toarray().ravel(), transformed_evidence[j].toarray().ravel())\n",
        "\n",
        "# # Calculate Euclidean distance between test claims and evidence\n",
        "# test_distance = np.zeros((test_claim_tfidf.shape[0], transformed_evidence.shape[0]))\n",
        "# for i in range(test_claim_tfidf.shape[0]):\n",
        "#     for j in range(transformed_evidence.shape[0]):\n",
        "#         test_distance[i, j] = euclidean(test_claim_tfidf[i].toarray().ravel(), transformed_evidence[j].toarray().ravel())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fzgteUN7rAmX"
      },
      "outputs": [],
      "source": [
        "def spliting_dataset(similarity, claim_texts, claim_evidences, evidence_texts, top_k=5, neg_ratio=1):\n",
        "\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    # Based on the similarity matrix, find the top k most similar evidence for each claim\n",
        "    for i in range(similarity.shape[0]):\n",
        "\n",
        "        claim_text = claim_texts[i]\n",
        "\n",
        "        # Find the top k most similar evidence\n",
        "        top_evidences = np.argsort(-similarity[i])[:top_k]\n",
        "\n",
        "        # Add the top k most similar evidence to the dataset, label as 1\n",
        "        for evidence_index in top_evidences:\n",
        "            evidence_text = evidence_texts[evidence_index]\n",
        "            dataset.append(\"[cls] \" + claim_text + \" [sep] \" + evidence_text)\n",
        "            labels.append(1)\n",
        "\n",
        "        # If the claim has evidences, add the evidence to the dataset, label as 1\n",
        "        if claim_evidences is not None:\n",
        "            for evidence_index in claim_evidences[i]:\n",
        "                evidence_text = evidence_texts[evidence_index]\n",
        "                dataset.append(\"[cls] \" + claim_text + \" [sep] \" + evidence_text)\n",
        "                labels.append(1)\n",
        "\n",
        "        # Randomly sample negative samples, label as 0\n",
        "        neg_samples_num = int(neg_ratio * len(top_evidences))\n",
        "\n",
        "        # Randomly sample negative samples that are not in the top k most similar evidence\n",
        "        neg_evidences = np.random.choice(\n",
        "            [j for j in range(similarity.shape[1]) if j not in top_evidences],\n",
        "            neg_samples_num\n",
        "        )\n",
        "\n",
        "        # Add the negative samples to the dataset\n",
        "        for evidence_index in neg_evidences:\n",
        "            evidence_text = evidence_texts[evidence_index]\n",
        "            dataset.append(\"[cls] \" + claim_text + \" [sep] \" + evidence_text)\n",
        "            labels.append(0)\n",
        "\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "1yZ4FGlrrAmX"
      },
      "outputs": [],
      "source": [
        "train_dataset, train_dataset_labels = spliting_dataset(\n",
        "    train_similarity, train_claim_text, train_claim_evidences, cleaned_evidence_text, top_k=10, neg_ratio=1.2\n",
        ")\n",
        "dev_dataset, dev_dataset_labels = spliting_dataset(\n",
        "    dev_similarity, dev_claim_text, None, cleaned_evidence_text, top_k=10, neg_ratio=1.2\n",
        ")\n",
        "test_dataset, test_dataset_labels = spliting_dataset(\n",
        "    test_similarity, test_claim_text, None, cleaned_evidence_text, top_k=10, neg_ratio=1.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZxkXsHUgb1g7"
      },
      "outputs": [],
      "source": [
        "# Convert the dataset labels to numpy array\n",
        "train_label_array = np.array(train_dataset_labels)\n",
        "dev_label_array = np.array(dev_dataset_labels)\n",
        "test_label_array = np.array(test_dataset_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a9pkJPuab1g8"
      },
      "outputs": [],
      "source": [
        "# need to install\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "ICh3nDmFb1g8"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  # 0 is padding token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "W2Sj6qFub1g8"
      },
      "outputs": [],
      "source": [
        "# Convert the text data to sequence\n",
        "train_sequence = tokenizer.texts_to_sequences(train_dataset)\n",
        "dev_sequence = tokenizer.texts_to_sequences(dev_dataset)\n",
        "test_sequence = tokenizer.texts_to_sequences(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "KCi9XwMPb1g8"
      },
      "outputs": [],
      "source": [
        "longest_train_sequence = 0\n",
        "for i in train_sequence:\n",
        "    longest_train_sequence = max(longest_train_sequence, len(i))\n",
        "\n",
        "longest_dev_sequence = 0\n",
        "for i in dev_sequence:\n",
        "    longest_dev_sequence = max(longest_dev_sequence, len(i))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "WQyglIFSb1hA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padding_length = max(longest_train_sequence, longest_dev_sequence) + 5\n",
        "\n",
        "padded_train_sequence = pad_sequences(train_sequence, maxlen=padding_length, padding='post')\n",
        "padded_dev_sequence = pad_sequences(dev_sequence, maxlen=padding_length, padding='post')\n",
        "padded_test_sequence = pad_sequences(test_sequence, maxlen=padding_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG_0JSzdb1hA",
        "outputId": "1c06eef2-a8ef-4473-f903-4c7110795bae"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'vocab_size' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m#model definition\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# feedforward network (MLP)\u001b[39;00m\n\u001b[0;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mretrieval_cls_lstm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mEmbedding(input_dim\u001b[38;5;241m=\u001b[39m\u001b[43mvocab_size\u001b[49m,\n\u001b[0;32m     16\u001b[0m                            output_dim\u001b[38;5;241m=\u001b[39membedding_dim,\n\u001b[0;32m     17\u001b[0m                            input_length\u001b[38;5;241m=\u001b[39mpadding_length, embeddings_regularizer\u001b[38;5;241m=\u001b[39ml2(\u001b[38;5;241m0.02\u001b[39m)))\n\u001b[0;32m     19\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# model.add(LSTM(hidden_dim, return_sequences=True, dropout=0.1))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# model.add(LSTM(hidden_dim, dropout=0.1))\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
          ]
        }
      ],
      "source": [
        "# from workshop\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "embedding_dim = 200\n",
        "hidden_dim = 400\n",
        "\n",
        "#model definition\n",
        "# feedforward network (MLP)\n",
        "model = Sequential(name=\"retrieval_cls_lstm\")\n",
        "model.add(layers.Embedding(input_dim=vocab_size,\n",
        "                           output_dim=embedding_dim,\n",
        "                           input_length=padding_length, embeddings_regularizer=l2(0.02)))\n",
        "\n",
        "model.add(layers.Dropout(0.5))\n",
        "# model.add(LSTM(hidden_dim, return_sequences=True, dropout=0.1))\n",
        "# model.add(LSTM(hidden_dim, dropout=0.1))\n",
        "\n",
        "model.add(layers.Bidirectional(LSTM(hidden_dim, return_sequences=True, dropout=0.5, kernel_regularizer=l2(0.02), recurrent_regularizer=l2(0.02))))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(hidden_dim, activation='tanh', kernel_regularizer=l2(0.02), bias_regularizer=l2(0.02)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#since it's a binary classification problem, we use a binary cross entropy loss here\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Recall()])\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "decay_steps = 3000\n",
        "learning_rate = 1e-5\n",
        "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    learning_rate, decay_steps\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE2RL1LOb1hA",
        "outputId": "46009bae-9fcd-44cb-aef4-0542b33e31c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "21/55 [==========>...................] - ETA: 5s - loss: 0.6892"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
            "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
            "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
            "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "model.fit(padded_train_sequence,train_label_array,epochs=15,validation_data=(padded_dev_sequence, dev_label_array),verbose=True,batch_size=500,callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "cUG6D3SPrAmZ"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "# model.save('retrieval_cls_lstm')\n",
        "\n",
        "# Load the model\n",
        "# model = tf.keras.models.load_model('retrieval_cls_lstm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AocxDzmKCJfx",
        "outputId": "67332018-710e-4d55-fd50-0825f465ada0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 1s 15ms/step\n",
            "53/53 [==============================] - 1s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "# Start prediction\n",
        "\n",
        "dev_predictions = model.predict(padded_dev_sequence, batch_size=64)\n",
        "test_predictions = model.predict(padded_test_sequence, batch_size=64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eA8lLFsWEnJ_",
        "outputId": "697d9989-e28c-4a05-b877-6c38c6f93814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]]\n",
            "[[0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]\n",
            " [0.45046675]]\n"
          ]
        }
      ],
      "source": [
        "print(dev_predictions[:20])\n",
        "print(test_predictions[:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "rvtdePsbCJfx"
      },
      "outputs": [],
      "source": [
        "def evidences_retrieval(claim_evidence_scores, top_k):\n",
        "\n",
        "    top_evidence_indices = []\n",
        "\n",
        "    for scores in claim_evidence_scores:\n",
        "        sorted_indices = np.argsort(scores)[::-1]\n",
        "        top_indices = sorted_indices[:top_k]\n",
        "        top_evidence_indices.append(top_indices)\n",
        "\n",
        "    return top_evidence_indices\n",
        "\n",
        "\n",
        "select_evidence_k = 6\n",
        "dev_top_evidence_indices = evidences_retrieval(dev_predictions, select_evidence_k)\n",
        "test_top_evidence_indices = evidences_retrieval(test_predictions, select_evidence_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "nmalyxnRCJfx"
      },
      "outputs": [],
      "source": [
        "# Update the dev JSON file\n",
        "with open('data/dev-claims.json', 'r') as f:\n",
        "    dev_claims = json.load(f)\n",
        "\n",
        "for claim_id, evidence_indices in zip(dev_claim_id, dev_top_evidence_indices):\n",
        "    top_evidence_ids = [cleaned_evidence_id[idx] for idx in evidence_indices]\n",
        "    dev_claims[claim_id]['evidences'] = top_evidence_ids\n",
        "\n",
        "with open('data/dev-claims.json', 'w') as f:\n",
        "    json.dump(dev_claims, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Zdpct1P9CJfx"
      },
      "outputs": [],
      "source": [
        "# Update the test JSON file\n",
        "with open('data/test-claims-unlabelled.json', 'r') as f:\n",
        "    test_claims = json.load(f)\n",
        "\n",
        "for claim_id, evidence_indices in zip(test_claim_id, test_top_evidence_indices):\n",
        "    top_evidence_ids = [cleaned_evidence_id[idx] for idx in evidence_indices]\n",
        "    test_claims[claim_id]['evidences'] = top_evidence_ids\n",
        "\n",
        "with open('data/test-claims-unlabelled.json', 'w') as f:\n",
        "    json.dump(test_claims, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIjj2SKenDh4",
        "outputId": "752a3386-e1ed-4f38-fdd5-ddc90bf80e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evidence Retrieval F-score (F): 0.0\n",
            "Claim Classification Accuracy (A): 0.38961038961038963\n",
            "Harmonic Mean of F and A: 0.0\n"
          ]
        }
      ],
      "source": [
        "# %%cmd\n",
        "# python eval.py --predictions dev-claims-baseline.json --groundtruth dev-claims.json\n",
        "# python eval.py --predictions dev_predict.json --groundtruth dev-claims.json\n",
        "\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# proc = subprocess.Popen([\"python\", \"eval.py\", \"--predictions\", \"data\\dev_predict.json\", \"--groundtruth\", \"data\\dev-claims.json\"\n",
        "# ], stdout=subprocess.PIPE, shell=True)\n",
        "# (out, err) = proc.communicate()\n",
        "# print(str(out))\n",
        "\n",
        "# 高自动化模型/预处理选择，可以自动读取准确度\n",
        "output = subprocess.check_output(\"python eval.py --predictions data/dev_predict.json --groundtruth data/dev-claims.json\", shell=True)\n",
        "output_str = output.decode('utf-8')\n",
        "\n",
        "# Split the output into lines\n",
        "output_lines = output_str.strip().split('\\n')\n",
        "\n",
        "# Format the output\n",
        "formatted_lines = []\n",
        "for line in output_lines:\n",
        "    metric, value = line.split('=')\n",
        "    metric = metric.strip()\n",
        "    value = value.strip()\n",
        "    formatted_line = f\"{metric}: {value}\"\n",
        "    formatted_lines.append(formatted_line)\n",
        "\n",
        "# Join the formatted lines into a single string\n",
        "formatted_output = '\\n'.join(formatted_lines)\n",
        "print(formatted_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
