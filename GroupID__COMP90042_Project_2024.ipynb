{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32yCsRUo8H33"
      },
      "source": [
        "# 2024 COMP90042 Project\n",
        "*Make sure you change the file name with your group id.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCybYoGz8YWQ"
      },
      "source": [
        "# Readme\n",
        "*If there is something to be noted for the marker, please mention here.*\n",
        "\n",
        "*If you are planning to implement a program with Object Oriented Programming style, please put those the bottom of this ipynb file*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_RZ3Oy5ylIE"
      },
      "source": [
        "# 0.Setting Colab Method for future model developing\n",
        "Firstly, run the following block to mount the drive to the colab. Then, drag the data folder/**eval.py** to the \"Colab Folder Space\" to ensure the code runs successfully.\n",
        "\n",
        "If data folder updated, attempt to forcibly remount, call `drive.mount(\"/content/drive\", force_remount=True)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBH7j4IHspgB",
        "outputId": "56611668-da3f-4157-9707-111dd751cc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6po98qVA8bJD"
      },
      "source": [
        "# 1.DataSet Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsRmNYMfb1g2"
      },
      "source": [
        "## 1.1 Reading and gathering data\n",
        "\n",
        "Using `json` package reading and gathering claims and evidences, then print an output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1N-PVoLb1g2",
        "outputId": "15670b2e-7fef-46f2-ae24-dea4041f043a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "claim count:  1228\n",
            "evidence count:  1208827\n",
            "max claim length:  332\n",
            "min claim length:  26\n",
            "mean claim length:  122.95521172638436\n",
            "max evidence count:  5\n",
            "min evidence count:  1\n",
            "mean evidence count:  3.3566775244299674\n",
            "max evidence length:  1979\n",
            "min evidence length:  13\n",
            "mean evidence length:  173.5\n",
            "Counter({'SUPPORTS': 519, 'NOT_ENOUGH_INFO': 386, 'REFUTES': 199, 'DISPUTED': 124})\n",
            "Dev evi inside train evi 163\n",
            "Dev evi outside train evi 328\n",
            "Train claim count:  1228\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "from statistics import mean\n",
        "\n",
        "with open('data/train-claims.json', 'r') as input_file:\n",
        "    train_claim_data = json.load(input_file)\n",
        "\n",
        "# Read in development data (claim)\n",
        "with open('data/dev-claims.json', 'r') as input_file:\n",
        "    dev_claim_data = json.load(input_file)\n",
        "\n",
        "# Read in test data (claim)\n",
        "with open('data/test-claims-unlabelled.json', 'r') as input_file:\n",
        "    test_claim_data = json.load(input_file)\n",
        "\n",
        "# Read in evidence data\n",
        "with open('data/evidence.json', 'r') as input_file:\n",
        "    evi_data = json.load(input_file)\n",
        "\n",
        "#EDA\n",
        "\n",
        "\n",
        "claim_count = 0\n",
        "evi_count = 0\n",
        "claim_length = []\n",
        "evidence_count = []\n",
        "evidence_length = []\n",
        "labels = []\n",
        "\n",
        "for key,value in train_claim_data.items():\n",
        "    claim_count+=1\n",
        "    claim_length.append(len(value[\"claim_text\"]))\n",
        "    evidence_count.append(len(value[\"evidences\"]))\n",
        "    evidence_length += [len(evi_data[x]) for x in value[\"evidences\"]]\n",
        "    labels.append(value[\"claim_label\"])\n",
        "\n",
        "for key,value in evi_data.items():\n",
        "    evi_count+=1\n",
        "\n",
        "print(\"claim count: \",claim_count)\n",
        "print(\"evidence count: \",evi_count)\n",
        "print(\"max claim length: \",max(claim_length))\n",
        "print(\"min claim length: \",min(claim_length))\n",
        "print(\"mean claim length: \",mean(claim_length))\n",
        "print(\"max evidence count: \",max(evidence_count))\n",
        "print(\"min evidence count: \",min(evidence_count))\n",
        "print(\"mean evidence count: \",mean(evidence_count))\n",
        "print(\"max evidence length: \",max(evidence_length))\n",
        "print(\"min evidence length: \",min(evidence_length))\n",
        "print(\"mean evidence length: \",mean(evidence_length))\n",
        "print(Counter(labels))\n",
        "\n",
        "\n",
        "\n",
        "inside = 0\n",
        "outside = 0\n",
        "\n",
        "train_evi_id = []\n",
        "for claim_id,claim_value in train_claim_data.items():\n",
        "    train_evi_id=train_evi_id+claim_value['evidences']\n",
        "\n",
        "for claim_id,claim_value in dev_claim_data.items():\n",
        "    test_evi_id=claim_value['evidences']\n",
        "    for e in test_evi_id:\n",
        "        if e in train_evi_id:\n",
        "            inside += 1\n",
        "        else:\n",
        "            outside += 1\n",
        "print(\"Dev evi inside train evi\", inside)\n",
        "print(\"Dev evi outside train evi\", outside)\n",
        "\n",
        "full_evidence_id = list(evi_data.keys())\n",
        "full_evidence_text  = list(evi_data.values())\n",
        "train_claim_id = list(train_claim_data.keys())\n",
        "train_claim_text  = [ v[\"claim_text\"] for v in train_claim_data.values()]\n",
        "print(\"Train claim count: \",len(train_claim_id))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpCxJ35-b1g3"
      },
      "source": [
        "## 1.2 Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGFcmSZmDlfE"
      },
      "source": [
        "### Implementing preprocessing fuctions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYaLwC2MDlfF",
        "outputId": "10c41a64-59c6-428f-88c3-7a11e794c2b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "def lemmatize(word):\n",
        "    lemma = lemmatizer.lemmatize(word, 'v')\n",
        "    return lemma if lemma != word else lemmatizer.lemmatize(word, 'n')\n",
        "\n",
        "def is_pure_english(text):\n",
        "    english_letters = set(string.ascii_letters)\n",
        "    cleaned_text = ''.join(char for char in text if char.isalpha() or char.isspace())\n",
        "    return all(char in english_letters or char.isspace() for char in cleaned_text)\n",
        "\n",
        "def remove_non_eng(dictionary):\n",
        "    eng_data = {}\n",
        "    for key, value in dictionary.items():\n",
        "        if is_pure_english(value):\n",
        "            eng_data[key] = value\n",
        "    return eng_data\n",
        "\n",
        "def contains_climate_keywords(text, keywords):\n",
        "    text = text.lower()\n",
        "    for keyword in keywords:\n",
        "        if re.search(r\"\\b\" + re.escape(keyword) + r\"\\b\", text):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "def filter_climate_related(dictionary, keywords):\n",
        "    cs_data = {}\n",
        "    for key, value in dictionary.items():\n",
        "        if contains_climate_keywords(value, keywords):\n",
        "            cs_data[key] = value\n",
        "    return cs_data\n",
        "\n",
        "def text_preprocessing(text, remove_stopwords=False):\n",
        "    words = [lemmatize(w) for w in text.lower().split()]\n",
        "    if remove_stopwords:\n",
        "        words = [w for w in words if w not in stopwords]\n",
        "    return \" \".join(words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqq0xrC_DlfF"
      },
      "source": [
        "### Implementing **Claim data preprocessing** and **Evidence data preprocessing** functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nsxYPxqgDlfF"
      },
      "outputs": [],
      "source": [
        "# 权威网站 https://www.ucdavis.edu/climate/definitions\n",
        "climate_keywords = [\n",
        "    \"climate\", \"environment\", \"global warming\", \"greenhouse effect\", \"carbon\", \"co2\", \"carbon dioxide\",\n",
        "    \"methane\", \"renewable energy\", \"sustainability\", \"ecology\", \"biodiversity\", \"fossil fuels\",\n",
        "    \"emissions\", \"air quality\", \"ozone\", \"solar energy\", \"wind energy\", \"climate change\", \"climate crisis\",\n",
        "    \"climate adaptation\", \"climate mitigation\", \"ocean\", \"sea levels\", \"ice melting\", \"deforestation\",\n",
        "    \"reforestation\", \"pollution\"\n",
        "]\n",
        "\n",
        "# def filter_evidence_by_train(train_claim_data, evidence_data):\n",
        "\n",
        "#     # Collect all evidence ids in the training set\n",
        "#     train_evidence_ids = set()\n",
        "\n",
        "#     for claim in train_claim_data.values():\n",
        "#         train_evidence_ids.update(claim['evidences'])\n",
        "\n",
        "#     # filter evidence data by the evidence ids in the training set\n",
        "#     filtered_evidence_data = {key: value for key, value in evidence_data.items() if key in train_evidence_ids}\n",
        "\n",
        "#     return filtered_evidence_data\n",
        "\n",
        "def preprocess_claim_data(claim_data, existed_evidences_id=None):\n",
        "    claim_data = remove_non_eng(claim_data)\n",
        "    claim_data_text = []\n",
        "    claim_data_id = []\n",
        "    claim_data_label = []\n",
        "    claim_evidences = []\n",
        "\n",
        "    for key in claim_data.keys():\n",
        "        claim_data[key][\"claim_text\"] = text_preprocessing(claim_data[key][\"claim_text\"])\n",
        "        claim_data_text.append(claim_data[key][\"claim_text\"])\n",
        "        claim_data_id.append(key)\n",
        "\n",
        "        if \"claim_label\" in claim_data[key]:\n",
        "            claim_data_label.append(claim_data[key][\"claim_label\"])\n",
        "        else:\n",
        "            claim_data_label.append(None)\n",
        "\n",
        "        if existed_evidences_id and \"evidences\" in claim_data[key]:\n",
        "            claim_evidences.append([existed_evidences_id[i] for i in claim_data[key][\"evidences\"]])\n",
        "        else:\n",
        "            claim_evidences.append([])\n",
        "\n",
        "    return claim_data_text, claim_data_id, claim_data_label, claim_evidences\n",
        "\n",
        "def preprocess_evi_data(evi_data, climate_keywords, train_claim_data):\n",
        "    evi_data = remove_non_eng(evi_data)\n",
        "    cs_evi_data = filter_climate_related(evi_data, climate_keywords)\n",
        "\n",
        "    # filter evidence data by the evidence ids in the training set\n",
        "    # train_evi_data = filter_evidence_by_train(train_claim_data, cs_evi_data)\n",
        "\n",
        "    for key in cs_evi_data.keys():\n",
        "        cs_evi_data[key] = text_preprocessing(cs_evi_data[key], remove_stopwords=True)\n",
        "\n",
        "    cleaned_evidence_text = list(cs_evi_data.values())\n",
        "    cleaned_evidence_id = list(cs_evi_data.keys())\n",
        "\n",
        "    return cleaned_evidence_text, cleaned_evidence_id\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rL8bIR_XDlfF"
      },
      "source": [
        "### Start dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0_ht7aH1DlfF"
      },
      "outputs": [],
      "source": [
        "# Preprocessing the claim data, split the data into text, id, label and evidences\n",
        "train_claim_text, train_claim_id, train_claim_label, train_claim_evidences = preprocess_claim_data(train_claim_data)\n",
        "\n",
        "dev_claim_text, dev_claim_id, dev_claim_label, dev_claim_evidences = preprocess_claim_data(dev_claim_data)\n",
        "\n",
        "test_claim_text, test_claim_id, _, _ = preprocess_claim_data(test_claim_data)\n",
        "\n",
        "# Preprocessing the evidence data, split the data into text and id\n",
        "cleaned_evidence_text, cleaned_evidence_id = preprocess_evi_data(evi_data, climate_keywords, train_claim_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "EL0R-_jaCJfv",
        "outputId": "8d6c6be2-fd20-4082-b8a3-1e2fae025416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train claim count:  1228\n",
            "Dev claim count:  154\n",
            "Test claim count:  153\n",
            "Evidence count:  19324\n"
          ]
        }
      ],
      "source": [
        "print(\"Train claim count: \",len(train_claim_text))\n",
        "print(\"Dev claim count: \",len(dev_claim_text))\n",
        "print(\"Test claim count: \",len(test_claim_text))\n",
        "print(\"Evidence count: \",len(cleaned_evidence_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3LL9-aEb1g5"
      },
      "source": [
        "## 1.3 Development Set Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g4cbdtTb1g5"
      },
      "source": [
        "In this section, we perform the main tasks of the project on the development set:\n",
        "\n",
        "1. **Evidence Retrieval**: For each claim, find the most relevant evidence from the corpus.\n",
        "2. **Claim Classification**: Predict the label for each claim based on the retrieved evidence and the claim's similarity to the training claims.\n",
        "\n",
        "The code uses TF-IDF vectorization and cosine similarity to measure the relevance between claims and evidence, and between development and training claims. The most similar evidence and training claims are used for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "6ZVeNYIH9IaL"
      },
      "outputs": [],
      "source": [
        "import operator\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.spatial.distance import euclidean\n",
        "\n",
        "# Creating two vectorizer\n",
        "claim_tfidf_vectorizer = TfidfVectorizer(max_features=10000, use_idf=True)\n",
        "evidence_tfidf_vectorizer = TfidfVectorizer(max_features=10000, use_idf=True)\n",
        "\n",
        "# fit the vectorizer on the evidence data\n",
        "evidence_tfidf_vectorizer.fit(cleaned_evidence_text)\n",
        "\n",
        "# Transform cleaned_evidence_text\n",
        "transformed_evidence = evidence_tfidf_vectorizer.transform(cleaned_evidence_text)\n",
        "\n",
        "# Transform claim data\n",
        "train_claim_tfidf = evidence_tfidf_vectorizer.transform(train_claim_text)\n",
        "dev_claim_tfidf = evidence_tfidf_vectorizer.transform(dev_claim_text)\n",
        "test_claim_tfidf = evidence_tfidf_vectorizer.transform(test_claim_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "58n5gcslrAmV"
      },
      "outputs": [],
      "source": [
        "# # Calculate cosine similarity between train claims and evidence\n",
        "# train_similarity = cosine_similarity(train_claim_tfidf, transformed_evidence)\n",
        "\n",
        "# # Calculate cosine similarity between dev claims and evidence\n",
        "# dev_similarity = cosine_similarity(dev_claim_tfidf, transformed_evidence)\n",
        "\n",
        "# # Calculate cosine similarity between test claims and evidence\n",
        "# test_similarity = cosine_similarity(test_claim_tfidf, transformed_evidence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Euclidean distance between train claims and evidence\n",
        "train_distance = np.zeros((train_claim_tfidf.shape[0], transformed_evidence.shape[0]))\n",
        "for i in range(train_claim_tfidf.shape[0]):\n",
        "    for j in range(transformed_evidence.shape[0]):\n",
        "        train_distance[i, j] = euclidean(train_claim_tfidf[i].toarray().ravel(), transformed_evidence[j].toarray().ravel())\n",
        "\n",
        "# Calculate Euclidean distance between dev claims and evidence\n",
        "dev_distance = np.zeros((dev_claim_tfidf.shape[0], transformed_evidence.shape[0]))\n",
        "for i in range(dev_claim_tfidf.shape[0]):\n",
        "    for j in range(transformed_evidence.shape[0]):\n",
        "        dev_distance[i, j] = euclidean(dev_claim_tfidf[i].toarray().ravel(), transformed_evidence[j].toarray().ravel())\n",
        "\n",
        "# Calculate Euclidean distance between test claims and evidence\n",
        "test_distance = np.zeros((test_claim_tfidf.shape[0], transformed_evidence.shape[0]))\n",
        "for i in range(test_claim_tfidf.shape[0]):\n",
        "    for j in range(transformed_evidence.shape[0]):\n",
        "        test_distance[i, j] = euclidean(test_claim_tfidf[i].toarray().ravel(), transformed_evidence[j].toarray().ravel())"
      ],
      "metadata": {
        "id": "ErcyOigvPc6k",
        "outputId": "813319b1-0d8a-4c6d-f7ed-6e93574f5f6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-3a6a14ff729e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_claim_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformed_evidence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mtrain_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_claim_tfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_evidence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Calculate Euclidean distance between dev claims and evidence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# Dispatch to specialized methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINT_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_intXint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FA2ao2l8hOg"
      },
      "source": [
        "# 2. Model Implementation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "fzgteUN7rAmX"
      },
      "outputs": [],
      "source": [
        "def spliting_dataset(similarity, claim_texts, claim_evidences, evidence_texts, top_k=5, neg_ratio=1):\n",
        "\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    # Based on the similarity matrix, find the top k most similar evidence for each claim\n",
        "    for i in range(similarity.shape[0]):\n",
        "\n",
        "        claim_text = claim_texts[i]\n",
        "\n",
        "        # Find the top k most similar evidence\n",
        "        top_evidences = np.argsort(-similarity[i])[:top_k]\n",
        "\n",
        "        # Add the top k most similar evidence to the dataset, label as 1\n",
        "        for evidence_index in top_evidences:\n",
        "            evidence_text = evidence_texts[evidence_index]\n",
        "            dataset.append(\"[cls] \" + claim_text + \" [sep] \" + evidence_text)\n",
        "            labels.append(1)\n",
        "\n",
        "        # If the claim has evidences, add the evidence to the dataset, label as 1\n",
        "        if claim_evidences is not None:\n",
        "            for evidence_index in claim_evidences[i]:\n",
        "                evidence_text = evidence_texts[evidence_index]\n",
        "                dataset.append(\"[cls] \" + claim_text + \" [sep] \" + evidence_text)\n",
        "                labels.append(1)\n",
        "\n",
        "        # Randomly sample negative samples, label as 0\n",
        "        neg_samples_num = int(neg_ratio * len(top_evidences))\n",
        "\n",
        "        # Randomly sample negative samples that are not in the top k most similar evidence\n",
        "        neg_evidences = np.random.choice(\n",
        "            [j for j in range(similarity.shape[1]) if j not in top_evidences],\n",
        "            neg_samples_num\n",
        "        )\n",
        "\n",
        "        # Add the negative samples to the dataset\n",
        "        for evidence_index in neg_evidences:\n",
        "            evidence_text = evidence_texts[evidence_index]\n",
        "            dataset.append(\"[cls] \" + claim_text + \" [sep] \" + evidence_text)\n",
        "            labels.append(0)\n",
        "\n",
        "    return dataset, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "1yZ4FGlrrAmX"
      },
      "outputs": [],
      "source": [
        "train_dataset, train_dataset_labels = spliting_dataset(\n",
        "    train_similarity, train_claim_text, train_claim_evidences, cleaned_evidence_text, top_k=10, neg_ratio=1.2\n",
        ")\n",
        "dev_dataset, dev_dataset_labels = spliting_dataset(\n",
        "    dev_similarity, dev_claim_text, None, cleaned_evidence_text, top_k=10, neg_ratio=1.2\n",
        ")\n",
        "test_dataset, test_dataset_labels = spliting_dataset(\n",
        "    test_similarity, test_claim_text, None, cleaned_evidence_text, top_k=10, neg_ratio=1.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ZxkXsHUgb1g7"
      },
      "outputs": [],
      "source": [
        "# Convert the dataset labels to numpy array\n",
        "train_label_array = np.array(train_dataset_labels)\n",
        "dev_label_array = np.array(dev_dataset_labels)\n",
        "test_label_array = np.array(test_dataset_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "a9pkJPuab1g8"
      },
      "outputs": [],
      "source": [
        "# need to install\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ICh3nDmFb1g8"
      },
      "outputs": [],
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1  # 0 is padding token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "W2Sj6qFub1g8"
      },
      "outputs": [],
      "source": [
        "# Convert the text data to sequence\n",
        "train_sequence = tokenizer.texts_to_sequences(train_dataset)\n",
        "dev_sequence = tokenizer.texts_to_sequences(dev_dataset)\n",
        "test_sequence = tokenizer.texts_to_sequences(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "KCi9XwMPb1g8"
      },
      "outputs": [],
      "source": [
        "longest_train_sequence = 0\n",
        "for i in train_sequence:\n",
        "    longest_train_sequence = max(longest_train_sequence, len(i))\n",
        "\n",
        "longest_dev_sequence = 0\n",
        "for i in dev_sequence:\n",
        "    longest_dev_sequence = max(longest_dev_sequence, len(i))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "WQyglIFSb1hA"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "padding_length = max(longest_train_sequence, longest_dev_sequence) + 5\n",
        "\n",
        "padded_train_sequence = pad_sequences(train_sequence, maxlen=padding_length, padding='post')\n",
        "padded_dev_sequence = pad_sequences(dev_sequence, maxlen=padding_length, padding='post')\n",
        "padded_test_sequence = pad_sequences(test_sequence, maxlen=padding_length, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UG_0JSzdb1hA",
        "outputId": "1c06eef2-a8ef-4473-f903-4c7110795bae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"retrieval_cls_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 165, 200)          3799800   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 165, 200)          0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 165, 800)          1923200   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Gl  (None, 800)               0         \n",
            " obalMaxPooling1D)                                               \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 400)               320400    \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 400)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 401       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6043801 (23.06 MB)\n",
            "Trainable params: 6043801 (23.06 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# from workshop\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "embedding_dim = 200\n",
        "hidden_dim = 400\n",
        "\n",
        "#model definition\n",
        "# feedforward network (MLP)\n",
        "model = Sequential(name=\"retrieval_cls_lstm\")\n",
        "model.add(layers.Embedding(input_dim=vocab_size,\n",
        "                           output_dim=embedding_dim,\n",
        "                           input_length=padding_length, embeddings_regularizer=l2(0.02)))\n",
        "\n",
        "model.add(layers.Dropout(0.6))\n",
        "# model.add(LSTM(hidden_dim, return_sequences=True, dropout=0.1))\n",
        "# model.add(LSTM(hidden_dim, dropout=0.1))\n",
        "\n",
        "model.add(layers.Bidirectional(LSTM(hidden_dim, return_sequences=True, dropout=0.6, kernel_regularizer=l2(0.02), recurrent_regularizer=l2(0.02))))\n",
        "model.add(layers.GlobalMaxPooling1D())\n",
        "\n",
        "model.add(layers.Dense(hidden_dim, activation='tanh', kernel_regularizer=l2(0.02), bias_regularizer=l2(0.02)))\n",
        "model.add(layers.Dropout(0.6))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#since it's a binary classification problem, we use a binary cross entropy loss here\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.Recall()])\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "decay_steps = 3000\n",
        "learning_rate = 1e-4\n",
        "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
        "    learning_rate, decay_steps\n",
        ")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='min')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DE2RL1LOb1hA",
        "outputId": "46009bae-9fcd-44cb-aef4-0542b33e31c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "86/86 [==============================] - 11s 89ms/step - loss: 82.7363 - val_loss: 63.3195\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 7s 81ms/step - loss: 49.6947 - val_loss: 37.8599\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 7s 81ms/step - loss: 29.5910 - val_loss: 22.4357\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 7s 81ms/step - loss: 17.4854 - val_loss: 13.2261\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 7s 81ms/step - loss: 10.3151 - val_loss: 7.8258\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 7s 81ms/step - loss: 6.1448 - val_loss: 4.7153\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 7s 80ms/step - loss: 3.7600 - val_loss: 2.9513\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 7s 80ms/step - loss: 2.4149 - val_loss: 1.9621\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 7s 80ms/step - loss: 1.6630 - val_loss: 1.4108\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 7s 80ms/step - loss: 1.2443 - val_loss: 1.1036\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79fce873eaa0>"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "model.fit(padded_train_sequence,train_label_array,epochs=10,validation_data=(padded_dev_sequence, dev_label_array),verbose=True,batch_size=300,callbacks=[earlystopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "cUG6D3SPrAmZ"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "# model.save('retrieval_cls_lstm')\n",
        "\n",
        "# Load the model\n",
        "# model = tf.keras.models.load_model('retrieval_cls_lstm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzGuzHPE87Ya"
      },
      "source": [
        "# 3.Testing and Evaluation\n",
        "(You can add as many code blocks and text blocks as you need. However, YOU SHOULD NOT MODIFY the section title)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "AocxDzmKCJfx",
        "outputId": "67332018-710e-4d55-fd50-0825f465ada0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26/26 [==============================] - 1s 11ms/step\n",
            "26/26 [==============================] - 0s 11ms/step\n"
          ]
        }
      ],
      "source": [
        "# Start prediction\n",
        "\n",
        "dev_predictions = model.predict(padded_dev_sequence, batch_size=128)\n",
        "test_predictions = model.predict(padded_test_sequence, batch_size=128)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dev_predictions[:20])\n",
        "print(test_predictions[:5])"
      ],
      "metadata": {
        "id": "eA8lLFsWEnJ_",
        "outputId": "697d9989-e28c-4a05-b877-6c38c6f93814",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.47876826]\n",
            " [0.47876838]\n",
            " [0.47876844]\n",
            " [0.47876686]\n",
            " [0.47876784]\n",
            " [0.4787682 ]\n",
            " [0.47876817]\n",
            " [0.4787672 ]\n",
            " [0.47876805]\n",
            " [0.47876793]\n",
            " [0.47876728]\n",
            " [0.47876853]\n",
            " [0.47876576]\n",
            " [0.47876745]\n",
            " [0.47876897]\n",
            " [0.47876784]\n",
            " [0.4787691 ]\n",
            " [0.4787675 ]\n",
            " [0.47876826]\n",
            " [0.4787662 ]]\n",
            "[[0.47876754]\n",
            " [0.47876936]\n",
            " [0.47876787]\n",
            " [0.4787708 ]\n",
            " [0.47876707]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "rvtdePsbCJfx"
      },
      "outputs": [],
      "source": [
        "def evidences_retrieval(claim_evidence_scores, top_k):\n",
        "\n",
        "    top_evidence_indices = []\n",
        "\n",
        "    for scores in claim_evidence_scores:\n",
        "        sorted_indices = np.argsort(scores)[::-1]\n",
        "        top_indices = sorted_indices[:top_k]\n",
        "        top_evidence_indices.append(top_indices)\n",
        "\n",
        "    return top_evidence_indices\n",
        "\n",
        "\n",
        "select_evidence_k = 6\n",
        "dev_top_evidence_indices = evidences_retrieval(dev_predictions, select_evidence_k)\n",
        "test_top_evidence_indices = evidences_retrieval(test_predictions, select_evidence_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "nmalyxnRCJfx"
      },
      "outputs": [],
      "source": [
        "# Update the dev JSON file\n",
        "with open('data/dev-claims.json', 'r') as f:\n",
        "    dev_claims = json.load(f)\n",
        "\n",
        "for claim_id, evidence_indices in zip(dev_claim_id, dev_top_evidence_indices):\n",
        "    top_evidence_ids = [cleaned_evidence_id[idx] for idx in evidence_indices]\n",
        "    dev_claims[claim_id]['evidences'] = top_evidence_ids\n",
        "\n",
        "with open('data/dev-claims.json', 'w') as f:\n",
        "    json.dump(dev_claims, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Zdpct1P9CJfx"
      },
      "outputs": [],
      "source": [
        "# Update the test JSON file\n",
        "with open('data/test-claims-unlabelled.json', 'r') as f:\n",
        "    test_claims = json.load(f)\n",
        "\n",
        "for claim_id, evidence_indices in zip(test_claim_id, test_top_evidence_indices):\n",
        "    top_evidence_ids = [cleaned_evidence_id[idx] for idx in evidence_indices]\n",
        "    test_claims[claim_id]['evidences'] = top_evidence_ids\n",
        "\n",
        "with open('data/test-claims-unlabelled.json', 'w') as f:\n",
        "    json.dump(test_claims, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VIjj2SKenDh4",
        "outputId": "752a3386-e1ed-4f38-fdd5-ddc90bf80e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evidence Retrieval F-score (F): 0.0\n",
            "Claim Classification Accuracy (A): 0.474025974025974\n",
            "Harmonic Mean of F and A: 0.0\n"
          ]
        }
      ],
      "source": [
        "# %%cmd\n",
        "# python eval.py --predictions dev-claims-baseline.json --groundtruth dev-claims.json\n",
        "# python eval.py --predictions dev_predict.json --groundtruth dev-claims.json\n",
        "\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# proc = subprocess.Popen([\"python\", \"eval.py\", \"--predictions\", \"data\\dev_predict.json\", \"--groundtruth\", \"data\\dev-claims.json\"\n",
        "# ], stdout=subprocess.PIPE, shell=True)\n",
        "# (out, err) = proc.communicate()\n",
        "# print(str(out))\n",
        "\n",
        "# 高自动化模型/预处理选择，可以自动读取准确度\n",
        "output = subprocess.check_output(\"python eval.py --predictions data/dev_predict.json --groundtruth data/dev-claims.json\", shell=True)\n",
        "output_str = output.decode('utf-8')\n",
        "\n",
        "# Split the output into lines\n",
        "output_lines = output_str.strip().split('\\n')\n",
        "\n",
        "# Format the output\n",
        "formatted_lines = []\n",
        "for line in output_lines:\n",
        "    metric, value = line.split('=')\n",
        "    metric = metric.strip()\n",
        "    value = value.strip()\n",
        "    formatted_line = f\"{metric}: {value}\"\n",
        "    formatted_lines.append(formatted_line)\n",
        "\n",
        "# Join the formatted lines into a single string\n",
        "formatted_output = '\\n'.join(formatted_lines)\n",
        "print(formatted_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mefSOe8eTmGP"
      },
      "source": [
        "## Object Oriented Programming codes here\n",
        "\n",
        "*You can use multiple code snippets. Just add more if needed*"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}